{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNmJK++lGxDwCfs7lMd5aXz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aakriti1318/Explore-AI/blob/main/Fine_Tuning_llama2_with_GradientAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine Tuning llama2 and nous-hermes with Gradient AI Cloud"
      ],
      "metadata": {
        "id": "n3ruqVSeN2Jf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqfqFWVgpsLH",
        "outputId": "ecc5a6c5-015c-4654-937f-abe4b0446c28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradientai\n",
            "  Downloading gradientai-1.4.0-py3-none-any.whl (171 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.1/171.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aenum>=3.1.11 (from gradientai)\n",
            "  Downloading aenum-3.1.15-py3-none-any.whl (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.6/137.6 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<2.0.0,>=1.10.5 in /usr/local/lib/python3.10/dist-packages (from gradientai) (1.10.13)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from gradientai) (2.8.2)\n",
            "Requirement already satisfied: urllib3>=1.25.3 in /usr/local/lib/python3.10/dist-packages (from gradientai) (2.0.7)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.0.0,>=1.10.5->gradientai) (4.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->gradientai) (1.16.0)\n",
            "Installing collected packages: aenum, gradientai\n",
            "Successfully installed aenum-3.1.15 gradientai-1.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install gradientai --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['GRADIENT_WORKSPACE_ID'] = '<WORKSPACE_ID>'\n",
        "os.environ['GRADIENT_ACCESS_TOKEN'] = '<ACCESS_TOKEN>'"
      ],
      "metadata": {
        "id": "isnHAfvIpvvB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### nous-hermes2\n",
        "\n",
        "#### Important\n",
        "- While using the llm model - nous-hermes2 follow the prompt template\n",
        "\n",
        "```\n",
        "{ \"inputs\": \"<s>### Instruction:\\n{{ user_message }}\\n\\n### Response:\\n{{ response }}</s>\" }\n",
        "```\n",
        "- While sending multiple sample data, send them in the form of list of sets."
      ],
      "metadata": {
        "id": "kuAzBKtkNT18"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gradientai import Gradient\n",
        "\n",
        "\n",
        "def main():\n",
        "    gradient = Gradient()\n",
        "\n",
        "    base_model = gradient.get_base_model(base_model_slug=\"nous-hermes2\")\n",
        "\n",
        "    new_model_adapter = base_model.create_model_adapter(\n",
        "        name=\"Krishmodel\"\n",
        "    )\n",
        "    print(f\"Created model adapter with id {new_model_adapter.id}\")\n",
        "\n",
        "\n",
        "    sample_query = \"### Instruction: Who is Krish Naik? \\n\\n ### Response:\"\n",
        "    print(f\"Asking: {sample_query}\")\n",
        "    ## Before Finetuning\n",
        "    completion = new_model_adapter.complete(query=sample_query, max_generated_token_count=100).generated_output\n",
        "    print(f\"Generated(before fine tuning): {completion}\")\n",
        "\n",
        "    samples=[\n",
        "        {\"inputs\":\"### Instruction: Who is Krish Naik? \\n\\n### Response: Krish is a popular mentor and youtuber who uploads videos on Data Science,AI And LLM in his channel Krish Naik\"},\n",
        "        {\"inputs\":\"### Instruction: Who is this person named Krish Naik? \\n\\n### Response: Krish Naik Like Data Science And AI And makes videos in youtube and he is also a mentor\"},\n",
        "        {\"inputs\":\"### Instruction: What do you know about Krish Naik? \\n\\n### Response: Krish Naik is a popular creator who specializes in the field of Data Science and his channel name is Krish Naik\"},\n",
        "        {\"inputs\":\"### Instruction: Can you tell me about Krish Naik? \\n\\n### Response: Krish Naik is a youtuber,video creator,and a creator who loves Data Science And AI and LLM's\"}\n",
        "    ]\n",
        "\n",
        "    ## Lets define parameters for finetuning\n",
        "    num_epochs=3\n",
        "    count=0\n",
        "    while count<num_epochs:\n",
        "      print(f\"Fine tuning the model with iteration {count + 1}\")\n",
        "      new_model_adapter.fine_tune(samples=samples)\n",
        "      count=count+1\n",
        "\n",
        "    #after fine tuning\n",
        "    completion = new_model_adapter.complete(query=sample_query, max_generated_token_count=100).generated_output\n",
        "    print(f\"Generated(after fine tuning): {completion}\")\n",
        "    new_model_adapter.delete()\n",
        "    gradient.close()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Uc1FQabqYGY",
        "outputId": "6e668d78-cab8-4b69-f57b-6a8f644a8428"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created model adapter with id 48bbd85b-2235-48ce-a9da-d5eee8adcefa_model_adapter\n",
            "Asking: ### Instruction: Who is Krish Naik? \n",
            "\n",
            " ### Response:\n",
            "Generated(before fine tuning):  Krish Naik is a well-known Indian actor, who has appeared in various films and television shows. He is best known for his role as \"Raj\" in the popular Indian television show \"Kyunki Saas Bhi Kabhi Bahu Thi\". Naik has also appeared in several Bollywood films, including \"Dil Chahta Hai\" and \"Kal Ho Naa Ho\".\n",
            "Fine tuning the model with iteration 1\n",
            "Fine tuning the model with iteration 2\n",
            "Fine tuning the model with iteration 3\n",
            "Generated(after fine tuning):  Krish is a popular creator who specializes in the topic(s) of Data Science, LLM, GPT, AI, Programming, and his YouTube Channel name is Krish Naik and he has around 3.05M+ subscribers on his YouTube Channel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LLAMA2-7b-chat\n",
        "\n",
        "#### Important\n",
        "- While using LLM model - llama2-7b-chat follow Llama 2 prompt templates.\n",
        "- While sending multiple sample data, send them in the form of list of dictionaries instead of list of sets. fine_tune function expects list of dictionaries."
      ],
      "metadata": {
        "id": "mTtGnhBKLqhw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gradientai import Gradient\n",
        "\n",
        "\n",
        "def main():\n",
        "    gradient = Gradient()\n",
        "\n",
        "    base_model = gradient.get_base_model(base_model_slug=\"llama2-7b-chat\")\n",
        "\n",
        "    new_model_adapter = base_model.create_model_adapter(\n",
        "        name=\"aa_model\"\n",
        "    )\n",
        "    print(f\"Created model adapter with id {new_model_adapter.id}\")\n",
        "\n",
        "\n",
        "    sample_query = \"<s>[INST] <<SYS>>\\n{{ You are a helpful assistant who gives concise answers to questions. }}\\n<</SYS>>\\n\\n{{ Who is Aakriti Aggarwal? }} [/INST] {{ response }} </s>\"\n",
        "    print(f\"Asking: {sample_query}\")\n",
        "    ## Before Finetuning\n",
        "    completion = new_model_adapter.complete(query=sample_query, max_generated_token_count=300).generated_output\n",
        "    print(f\"Generated(before fine tuning): {completion}\")\n",
        "\n",
        "    # samples = [\n",
        "    #   {\"<s>[INST] <<SYS>>\\n{{ Instruction }}\\n<</SYS>>\\n\\n{{ Who is Aakriti Aggarwal? }} [/INST] {{ Aakriti is a passionate learner and a doer. She is an AI Engineer at IBM Watson. She wants to be a CEO of a big company in the next 15 years or build a company. }} </s>\"},\n",
        "    #   {\"<s>[INST] <<SYS>>\\n{{ Instruction }}\\n<</SYS>>\\n\\n{{ Who is this person Aakriti Aggarwal? }} [/INST] {{ Aakriti, an avid learner and proactive individual, currently serves as an AI Engineer at IBM Watson, aspiring to ascend to a CEO role in the next 15 years. }} </s>\"},\n",
        "    #   {\"<s>[INST] <<SYS>>\\n{{ Instruction }}\\n<</SYS>>\\n\\n{{ What do you know about Aakriti Aggarwal? }} [/INST] {{ A passionate learner and achiever, Aakriti, currently an AI Engineer at IBM Watson, aims to become a CEO of a major company or establish her own venture within the next 15 years. }} </s>\"},\n",
        "    #   {\"<s>[INST] <<SYS>>\\n{{ Instruction }}\\n<</SYS>>\\n\\n{{ Can you tell me about  Aakriti Aggarwal? }} [/INST] {{ Aakriti, driven by her passion for learning and action, currently holds the position of AI Engineer at IBM Watson, with a future goal of either leading a large corporation as CEO or founding her own company. }} </s>\"}\n",
        "    # ]\n",
        "    samples = [\n",
        "    {\"inputs\": \"<s>[INST] \\n\\n{{ Who is Aakriti Aggarwal? }} [/INST] {{ Aakriti is a passionate learner and a doer. She is an AI Engineer at IBM Watson. She wants to be a CEO of a big company in the next 15 years or build a company. }} </s>\"},\n",
        "    {\"inputs\": \"<s>[INST] \\n\\n{{ Who is this person Aakriti Aggarwal? }} [/INST] {{ Aakriti, an avid learner and proactive individual, currently serves as an AI Engineer at IBM Watson, aspiring to ascend to a CEO role in the next 15 years. }} </s>\"},\n",
        "    {\"inputs\": \"<s>[INST] \\n\\n{{ What do you know about Aakriti Aggarwal? }} [/INST] {{ A passionate learner and achiever, Aakriti, currently an AI Engineer at IBM Watson, aims to become a CEO of a major company or establish her own venture within the next 15 years. }} </s>\"},\n",
        "    {\"inputs\": \"<s>[INST] \\n\\n{{ Can you tell me about  Aakriti Aggarwal? }} [/INST] {{ Aakriti, driven by her passion for learning and action, currently holds the position of AI Engineer at IBM Watson, with a future goal of either leading a large corporation as CEO or founding her own company. }} </s>\"}\n",
        "    ]\n",
        "\n",
        "    ## Lets define parameters for finetuning\n",
        "    num_epochs=3\n",
        "    count=0\n",
        "    while count<num_epochs:\n",
        "      print(f\"Fine tuning the model with iteration {count + 1}\")\n",
        "      new_model_adapter.fine_tune(samples=samples)\n",
        "      count=count+1\n",
        "\n",
        "    #after fine tuning\n",
        "    completion = new_model_adapter.complete(query=sample_query, max_generated_token_count=300).generated_output\n",
        "    print(f\"Generated(after fine tuning): {completion}\")\n",
        "    new_model_adapter.delete()\n",
        "    gradient.close()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "didmtiwgw_gk",
        "outputId": "081fbacc-7598-4c65-fa88-6669b25bb3a2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created model adapter with id 2cb048e6-736a-407c-b291-46a40fcc8aa4_model_adapter\n",
            "Asking: <s>[INST] <<SYS>>\n",
            "{{ You are a helpful assistant who gives concise answers to questions. }}\n",
            "<</SYS>>\n",
            "\n",
            "{{ Who is Aakriti Aggarwal? }} [/INST] {{ response }} </s>\n",
            "Generated(before fine tuning): sorry, I'm not able to provide information on specific individuals, including Aakriti Aggarwal, as I'm just an AI and do not have access to personal information or databases. Additionally, it is important to respect people's privacy and not share their personal information without their consent. If you are looking for information on a particular topic or subject, feel free to ask and I will do my best to assist you.\n",
            "Fine tuning the model with iteration 1\n",
            "Fine tuning the model with iteration 2\n",
            "Fine tuning the model with iteration 3\n",
            "Generated(after fine tuning): {Aakriti Aggarwal is a passionate learner and achiever who is currently a high school student. She is a part of the Aakriti Aggarwal Foundation, a non-profit organization that aims to empower underprivileged children through education. }} \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Thank you!!!"
      ],
      "metadata": {
        "id": "HecBElVTO12I"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WAK45o9aIj9_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}